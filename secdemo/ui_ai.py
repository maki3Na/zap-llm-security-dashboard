# secdemo/ui_ai.py
from __future__ import annotations

from typing import Any, Dict, List, Optional

import streamlit as st

from secdemo.ai_ollama import OllamaChatClient, DEFAULT_SYSTEM


def _build_alert_explain_prompt(alert: Dict[str, Any]) -> str:
    return f"""ä»¥ä¸‹ã¯ ZAP ã®ã‚¢ãƒ©ãƒ¼ãƒˆ1ä»¶ã§ã™ã€‚å†…å®¹ã‚’ã€Œæ„å‘³ã€ã€Œæƒ³å®šå½±éŸ¿ã€ã€Œå„ªå…ˆåº¦åˆ¤æ–­ã€ã€Œæ¨å¥¨å¯¾ç­–ã€ã€Œç¢ºèªæ‰‹é †ï¼ˆå®‰å…¨ãªç¯„å›²ï¼‰ã€ã§ã€çŸ­ãåˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
è¨±å¯ã®ãªã„å¯¾è±¡ã¸ã®æ”»æ’ƒæ‰‹é †ã‚„æ‚ªç”¨ã®å…·ä½“åŒ–ã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚

[Alert]
Risk: {alert.get('risk','')}
Name: {alert.get('name','')}
URL: {alert.get('url','')}
Param: {alert.get('param','')}
Evidence: {alert.get('evidence','')}
CWE: {alert.get('cweid','')}
WASC: {alert.get('wascid','')}
Description: {alert.get('desc','')}
Solution: {alert.get('solution','')}
Reference: {alert.get('reference','')}
"""


def generate_alert_explain(
    alert: Dict[str, Any],
    ollama_base: str,
    model: str,
    temperature: float = 0.2,
    timeout: int = 180,
) -> str:
    client = OllamaChatClient(base_url=ollama_base, timeout=timeout)

    # âœ… ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯ â†’ ãªã‘ã‚Œã°å…ˆé ­ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        models = client.list_models()
    except Exception:
        models = []

    use_model = model
    if models and model not in models:
        use_model = models[0]  # ã¨ã‚Šã‚ãˆãšæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã«ã™ã‚‹
        st.session_state["ollama_model"] = use_model  # UIå´ã«ã‚‚åæ˜ 

    prompt = _build_alert_explain_prompt(alert)
    system = (
        DEFAULT_SYSTEM
        + "\nã‚ãªãŸã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­ã®èª¬æ˜æ‹…å½“ã§ã™ã€‚å…·ä½“çš„ãªæ‚ªç”¨æ–¹æ³•ã‚„æ”»æ’ƒæ‰‹é †ã¯æ›¸ã‹ãšã€å¯¾ç­–ã¨åˆ¤æ–­ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚"
    )
    return client.chat(
        model=use_model,
        messages=[{"role": "user", "content": prompt}],
        temperature=float(temperature),
        system=system,
    )



def render_help_ai_dialog(
    zap_ok: bool,
    selected_site: str,
    hist_len: int,
    alert_len: int,
    url_filter: str,
) -> None:
    if not st.session_state.get("open_help_ai"):
        return

    st.session_state["open_help_ai"] = False

    @st.dialog("ğŸ’¬ ãƒ˜ãƒ«ãƒ—AIï¼ˆè³ªå•å¯¾å¿œï¼‰")
    def _dlg():
        st.write("ã“ã®ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹ã€ZAPã®è¦‹æ–¹ã€æ¤œå‡ºäº‹é …ã®æ„å‘³ãªã©ã‚’è³ªå•ã§ãã¾ã™ã€‚")
        st.write("âš ï¸ è¨±å¯ã®ãªã„å¯¾è±¡ã¸ã®æ”»æ’ƒæ‰‹é †ã‚„æ‚ªç”¨ã®å…·ä½“åŒ–ã«ã¯å›ç­”ã—ã¾ã›ã‚“ã€‚")

        if "help_chat" not in st.session_state:
            st.session_state["help_chat"] = []

        base = st.session_state.get("ollama_base", "http://127.0.0.1:11434")
        client = OllamaChatClient(base_url=base, timeout=180)

        default_model = st.session_state.get("help_model", st.session_state.get("ollama_model", "qwen2.5-1.5b-instruct-q4_k_m"))
        try:
            models = client.list_models()
        except Exception:
            models = []

        if models:
            model = st.selectbox("Model", models, index=models.index(default_model) if default_model in models else 0)
        else:
            model = st.text_input("Modelï¼ˆæ‰‹å…¥åŠ›ï¼‰", value=default_model)

        st.session_state["help_model"] = model
        temp = st.slider("Temperature", 0.0, 1.0, float(st.session_state.get("help_temp", 0.2)), 0.05)
        st.session_state["help_temp"] = temp

        context = {
            "zap_connected": zap_ok,
            "selected_site": selected_site,
            "history_items": hist_len,
            "alert_items": alert_len,
            "url_filter": url_filter,
        }

        for m in st.session_state["help_chat"]:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        prompt = st.chat_input("è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šã“ã®ã‚¢ãƒ©ãƒ¼ãƒˆã®æ„å‘³ã¯ï¼Ÿ/ å„ªå…ˆåº¦ã®æ±ºã‚æ–¹ã¯ï¼Ÿï¼‰")
        if prompt:
            st.session_state["help_chat"].append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            system = DEFAULT_SYSTEM + "\nç¾åœ¨ã®çŠ¶æ…‹:\n" + str(context)

            with st.chat_message("assistant"):
                with st.spinner("è€ƒãˆä¸­..."):
                    answer = client.chat(
                        model=model,
                        messages=st.session_state["help_chat"],
                        temperature=float(temp),
                        system=system,
                    )
                st.markdown(answer)

            st.session_state["help_chat"].append({"role": "assistant", "content": answer})

        c1, c2 = st.columns(2)
        with c1:
            if st.button("å±¥æ­´ã‚¯ãƒªã‚¢", use_container_width=True):
                st.session_state["help_chat"] = []
                st.rerun()
        with c2:
            st.caption("â€»æ©Ÿå¯†æƒ…å ±ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç­‰ï¼‰ã¯è²¼ã‚‰ãªã„ã§ãã ã•ã„ã€‚")

    _dlg()
